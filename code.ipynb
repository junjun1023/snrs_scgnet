{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "olive-defensive",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import segmentation_models_pytorch as smp\n",
    "from torch.utils.data import DataLoader, Subset, ConcatDataset\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "contemporary-blank",
   "metadata": {},
   "outputs": [],
   "source": [
    "import model\n",
    "import dataset\n",
    "import augmentation as aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "inclusive-course",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# helper function for data visualization\n",
    "def visualize(**images):\n",
    "    \"\"\"PLot images in one row.\"\"\"\n",
    "    n = len(images)\n",
    "    plt.figure(figsize=(16, 5))\n",
    "    for i, (name, image) in enumerate(images.items()):\n",
    "        plt.subplot(1, n, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title(' '.join(name.split('_')).title())\n",
    "        plt.imshow(image, 'gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "brazilian-batman",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, optimizer, dataloader, device):\n",
    "\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0\n",
    "    \n",
    "    dice_loss = smp.utils.losses.DiceLoss()\n",
    "\n",
    "    for index, data in tqdm(enumerate(dataloader)):\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        img, msk, _ = data\n",
    "\n",
    "        img = img.to(device)\n",
    "        msk = msk.to(device)\n",
    "\n",
    "        pr, scg_loss = model(img)\n",
    "\n",
    "        ### Predicted mask loss\n",
    "        pr = pr.squeeze(1)\n",
    "\n",
    "        loss = dice_loss(y_pred=pr, y_true=img) + scg_loss\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "\n",
    "    total_loss = total_loss/(index+1)\n",
    "\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "complex-operation",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def eval_epoch(model, dataloader, device):\n",
    "\n",
    "    import math\n",
    "    from torch.utils.data import DataLoader\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    iou_score = []\n",
    "    \n",
    "    metric_iou = smp.utils.metrics.IoU()\n",
    "\n",
    "    for index, data in tqdm(enumerate(dataloader)):\n",
    "\n",
    "        img, msk, _ = data\n",
    "\n",
    "        img = img.to(device)\n",
    "        msk = msk.to(device)\n",
    "\n",
    "        pr = model(img)\n",
    "        iou = metric_iou(pr, msk)\n",
    "\n",
    "        iou_score.append(iou.item())\n",
    "\n",
    "    return sum(iou_score)/len(iou_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "forbidden-queue",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test_epoch(model, dataset, device):\n",
    "\n",
    "    import math\n",
    "    from torch.utils.data import DataLoader\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    imgs = []\n",
    "    predict = []\n",
    "    msks = []\n",
    "\n",
    "    dataloader = DataLoader(dataset, batch_size=1,\n",
    "                            shuffle=False, num_workers=2)\n",
    "\n",
    "    for index, data in tqdm(enumerate(dataloader)):\n",
    "\n",
    "        img, msk, cpy = data\n",
    "\n",
    "        img = img.to(device)\n",
    "        msk = msk.to(device)\n",
    "\n",
    "        pr = model(img)\n",
    "\n",
    "        pr = torch.squeeze(pr, dim=0).detach().cpu().numpy()\n",
    "        msk = torch.squeeze(msk, dim=0).detach().cpu().numpy()\n",
    "        cpy = torch.squeeze(cpy, dim=0).detach().cpu().numpy()\n",
    "\n",
    "        predict.append(pr.transpose(1, 2, 0))\n",
    "        imgs.append(cpy.transpose(1, 2, 0))\n",
    "        msks.append(msk)\n",
    "\n",
    "\n",
    "    return imgs, predict, msks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eastern-romantic",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 8\n",
    "n_channels = 3\n",
    "n_classes = 1\n",
    "epochs = 1000\n",
    "\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "grand-studio",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENCODER = 'densenet161'\n",
    "ENCODER_WEIGHTS = 'imagenet'\n",
    "\n",
    "preprocessing_fn = smp.encoders.get_preprocessing_fn(ENCODER, ENCODER_WEIGHTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "velvet-auditor",
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = smp.Unet(encoder_name=ENCODER, \n",
    "                 encoder_weights=ENCODER_WEIGHTS,\n",
    "                decoder_attention_type=None,\n",
    "                 in_channels=3, classes=1, activation=\"sigmoid\", aux_params=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "tutorial-genius",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = unet.encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "knowing-taiwan",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = model.SCGDecoder(None, None, torch.nn.Sigmoid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advance-supervisor",
   "metadata": {},
   "outputs": [],
   "source": [
    "scg_net = model.SCGNet(encoder=encoder, \n",
    "               decoder=decoder,).to(device)\n",
    "\n",
    "optimizer = torch.optim.SGD(scg_net.parameters(), lr=1e-3, momentum=0.9, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "isolated-dover",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainset = dataset.JSRTset(root=os.path.join(os.getcwd(), \"data\", \"trainset\"),\n",
    "                          augmentation=aug.get_training_augmentation(), \n",
    "                           preprocessing=aug.get_preprocessing(preprocessing_fn),)\n",
    "valset = dataset.JSRTset(root=os.path.join(os.getcwd(), \"data\", \"valset\"),\n",
    "                          augmentation=aug.get_validation_augmentation(), \n",
    "                           preprocessing=aug.get_preprocessing(preprocessing_fn),)\n",
    "testset = dataset.JSRTset(root=os.path.join(os.getcwd(), \"data\", \"testset\"),\n",
    "                          augmentation=aug.get_validation_augmentation(), \n",
    "                           preprocessing=aug.get_preprocessing(preprocessing_fn),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sublime-pottery",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(trainset, batch_size=batch, shuffle=True, num_workers=2)\n",
    "validloader = DataLoader(valset, batch_size=batch, shuffle=False, num_workers=2)\n",
    "testloader = DataLoader(testset, batch_size=batch, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "urban-boundary",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lined-niger",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "placed-debate",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_logs = {\n",
    "    \"loss\": [],\n",
    "    \"iou-train\": [],\n",
    "    \"iou-valid\": []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electronic-allergy",
   "metadata": {},
   "outputs": [],
   "source": [
    "iou_valid = 0.0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    loss = train_epoch(unet, optimizer, trainloader, device)\n",
    "    eval_train = eval_epoch(unet, trainloader, device)\n",
    "    eval_valid = eval_epoch(unet, validloader, device)\n",
    "    \n",
    "    print(\"Epoch: {}, dice loss={:.5f}\".format(epoch, loss))\n",
    "    print(\"Valid-IoU: {:.5f}, Train-IoU: {:.5f}\".format(eval_valid, eval_train))\n",
    "    \n",
    "    epoch_logs['loss'].append(loss)\n",
    "    epoch_logs['iou-train'].append(eval_train)\n",
    "    epoch_logs['iou-valid'].append(eval_valid)\n",
    "   \n",
    "    if epoch == int(epochs*0.5):\n",
    "        optimizer.param_groups[0]['lr'] = 1e-4\n",
    "        print('Decrease learning rate to 1e-4!')\n",
    "    elif epoch == int(epochs*0.75):\n",
    "        optimizer.param_groups[0]['lr'] = 1e-5\n",
    "        print('Decrease learning rate to 1e-5!')\n",
    "        \n",
    "    if eval_valid > iou_valid:\n",
    "        iou_valid = eval_valid\n",
    "        checkpoint = {\n",
    "            'model_stat': unet.state_dict(),\n",
    "            'optimizer_stat': optimizer.state_dict(),\n",
    "        }\n",
    "        torch.save(checkpoint, os.path.join(os.getcwd(), \"{:04d}_{:04d}_{:04d}.pth\".format(int(eval_valid*1000),\n",
    "                                                                                   int(eval_train*1000),\n",
    "                                                                                   int(loss*1000))))\n",
    "        print(\"Model Saved\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "institutional-prairie",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "computational-nitrogen",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broadband-liverpool",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transparent-greenhouse",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naughty-skiing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "macro-track",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disciplinary-influence",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "useful-request",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
