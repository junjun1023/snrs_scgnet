{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "successful-practitioner",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import segmentation_models_pytorch as smp\n",
    "from torch.utils.data import DataLoader, Subset, ConcatDataset\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "helpful-chase",
   "metadata": {},
   "outputs": [],
   "source": [
    "import model\n",
    "import dataset\n",
    "import augmentation as aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "unavailable-quick",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# helper function for data visualization\n",
    "def visualize(**images):\n",
    "    \"\"\"PLot images in one row.\"\"\"\n",
    "    n = len(images)\n",
    "    plt.figure(figsize=(16, 5))\n",
    "    for i, (name, image) in enumerate(images.items()):\n",
    "        plt.subplot(1, n, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title(' '.join(name.split('_')).title())\n",
    "        plt.imshow(image, 'gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "seasonal-potential",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, optimizer, dataloader, device):\n",
    "\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0\n",
    "    \n",
    "    dice_total = 0\n",
    "    kl_total = 0\n",
    "    dl_total = 0\n",
    "    bce_total = 0\n",
    "    \n",
    "    dice_loss = smp.utils.losses.DiceLoss()\n",
    "#     bce_loss = torch.nn.BCELoss(reduction='none')\n",
    "\n",
    "    for index, data in tqdm(enumerate(dataloader)):\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        img, msk, _ = data\n",
    "\n",
    "        img = img.to(device)\n",
    "        msk = msk.to(device, dtype=torch.float)\n",
    "\n",
    "        pr, kl_loss, dl_loss = model(img)\n",
    "\n",
    "        ### Predicted mask loss\n",
    "        pr = pr.squeeze(1)\n",
    "\n",
    "\n",
    "        dice = dice_loss(pr, msk)\n",
    "        \n",
    "        ### bce loss\n",
    "#         bce = bce_loss(pr, msk)\n",
    "#         weight = msk.clone().detach()\n",
    "#         weight = torch.where(weight == 1, 100, 1)\n",
    "#         bce = bce * weight # weighted foreground/background\n",
    "#         bce = torch.mean(bce)\n",
    "        \n",
    "        kl = torch.mean(kl_loss)\n",
    "        dl = torch.mean(dl_loss)\n",
    "\n",
    "\n",
    "        loss = dice + kl + dl\n",
    "#         loss = bce + kl + dl\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        dice_total += dice.item()\n",
    "#         bce_total += bce.item()\n",
    "        kl_total += kl.item()\n",
    "        dl_total += dl.item()\n",
    "\n",
    "    total_loss = total_loss/(index+1)\n",
    "    dice_total = dice_total/(index+1)\n",
    "#     bce_total = bce_total/(index+1)\n",
    "    kl_total = kl_total/(index+1)\n",
    "    dl_total = dl_total/(index+1)\n",
    "\n",
    "    return total_loss, dice_total, kl_total, dl_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "included-location",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def eval_epoch(model, dataloader, device):\n",
    "\n",
    "    import math\n",
    "    from torch.utils.data import DataLoader\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    iou_score = []\n",
    "    \n",
    "    metric_iou = smp.utils.metrics.IoU()\n",
    "\n",
    "    for index, data in tqdm(enumerate(dataloader)):\n",
    "\n",
    "        img, msk, _ = data\n",
    "\n",
    "        img = img.to(device)\n",
    "        msk = msk.to(device)\n",
    "\n",
    "        pr, _, _ = model(img)\n",
    "        iou = metric_iou(pr, msk)\n",
    "\n",
    "        iou_score.append(iou.item())\n",
    "\n",
    "    return sum(iou_score)/len(iou_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "great-being",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test_epoch(model, dataset, device):\n",
    "\n",
    "    import math\n",
    "    from torch.utils.data import DataLoader\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    imgs = []\n",
    "    predict = []\n",
    "    msks = []\n",
    "\n",
    "    dataloader = DataLoader(dataset, batch_size=1,\n",
    "                            shuffle=False, num_workers=2)\n",
    "\n",
    "    for index, data in tqdm(enumerate(dataloader)):\n",
    "\n",
    "        img, msk, cpy = data\n",
    "\n",
    "        img = img.to(device)\n",
    "        msk = msk.to(device)\n",
    "\n",
    "        pr = model(img)\n",
    "\n",
    "        pr = torch.squeeze(pr, dim=0).detach().cpu().numpy()\n",
    "        msk = torch.squeeze(msk, dim=0).detach().cpu().numpy()\n",
    "        cpy = torch.squeeze(cpy, dim=0).detach().cpu().numpy()\n",
    "\n",
    "        predict.append(pr.transpose(1, 2, 0))\n",
    "        imgs.append(cpy.transpose(1, 2, 0))\n",
    "        msks.append(msk)\n",
    "\n",
    "\n",
    "    return imgs, predict, msks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fatty-mission",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 4\n",
    "n_channels = 3\n",
    "n_classes = 1\n",
    "epochs = 1000\n",
    "\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ceramic-kennedy",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENCODER = 'densenet161'\n",
    "ENCODER_WEIGHTS = 'imagenet'\n",
    "\n",
    "preprocessing_fn = smp.encoders.get_preprocessing_fn(ENCODER, ENCODER_WEIGHTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "increasing-madagascar",
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = smp.Unet(encoder_name=ENCODER, \n",
    "                 encoder_weights=ENCODER_WEIGHTS,\n",
    "                decoder_attention_type=None,\n",
    "                 in_channels=3, classes=1, activation=\"sigmoid\", aux_params=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "challenging-catch",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = unet.encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "characteristic-reporter",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = model.SCGDecoder(None, None, torch.nn.Sigmoid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "crude-redhead",
   "metadata": {},
   "outputs": [],
   "source": [
    "scg_net = model.SCGNet(encoder=encoder, \n",
    "               decoder=decoder,).to(device)\n",
    "\n",
    "optimizer = torch.optim.SGD(scg_net.parameters(), lr=1e-4, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "injured-casting",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainset = dataset.JSRTset(root=os.path.join(os.getcwd(), \"data\", \"trainset\"),\n",
    "                          augmentation=aug.get_training_augmentation(), \n",
    "                           preprocessing=aug.get_preprocessing(preprocessing_fn),)\n",
    "valset = dataset.JSRTset(root=os.path.join(os.getcwd(), \"data\", \"valset\"),\n",
    "                          augmentation=aug.get_validation_augmentation(), \n",
    "                           preprocessing=aug.get_preprocessing(preprocessing_fn),)\n",
    "testset = dataset.JSRTset(root=os.path.join(os.getcwd(), \"data\", \"testset\"),\n",
    "                          augmentation=aug.get_validation_augmentation(), \n",
    "                           preprocessing=aug.get_preprocessing(preprocessing_fn),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "terminal-yellow",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(trainset, batch_size=batch, shuffle=True, num_workers=2)\n",
    "validloader = DataLoader(valset, batch_size=batch, shuffle=False, num_workers=2)\n",
    "testloader = DataLoader(testset, batch_size=batch, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neutral-boston",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "removed-sullivan",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "organized-morrison",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_logs = {\n",
    "    \"diceloss\": [],\n",
    "#     \"bce loss\":[],\n",
    "    \"kl divergence\": [],\n",
    "    \"diagonal loss\": [],\n",
    "    \"iou-train\": [],\n",
    "    \"iou-valid\": []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "given-juice",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "41it [00:09,  4.30it/s]\n",
      "3it [00:00,  4.24it/s]"
     ]
    }
   ],
   "source": [
    "iou_valid = 0.0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    loss = train_epoch(scg_net, optimizer, trainloader, device)\n",
    "    eval_train = eval_epoch(scg_net, trainloader, device)\n",
    "    eval_valid = eval_epoch(scg_net, validloader, device)\n",
    "    \n",
    "    print(\"Epoch: {}, total loss={:.5f}, dice loss={:.5f}, kl loss={:.5f}, dl loss={:.5f}\".format(epoch, \n",
    "                                                                                                  loss[0],\n",
    "                                                                                                 loss[1],\n",
    "                                                                                                 loss[2],\n",
    "                                                                                                 loss[3]))\n",
    "    print(\"Valid-IoU: {:.5f}, Train-IoU: {:.5f}\".format(eval_valid, eval_train))\n",
    "    \n",
    "    epoch_logs['diceloss'].append(loss[1])\n",
    "#     epoch_logs[\"bce loss\"].append(loss[1])\n",
    "    epoch_logs['kl divergence'].append(loss[2])\n",
    "    epoch_logs['diagonal loss'].append(loss[3])\n",
    "    epoch_logs['iou-train'].append(eval_train)\n",
    "    epoch_logs['iou-valid'].append(eval_valid)\n",
    "   \n",
    "    if epoch == int(epochs*0.5):\n",
    "        optimizer.param_groups[0]['lr'] = 5e-5\n",
    "        print('Decrease learning rate to 1e-4!')\n",
    "    elif epoch == int(epochs*0.75):\n",
    "        optimizer.param_groups[0]['lr'] = 1e-6\n",
    "        print('Decrease learning rate to 1e-5!')\n",
    "        \n",
    "    if eval_valid > iou_valid:\n",
    "        iou_valid = eval_valid\n",
    "        checkpoint = {\n",
    "            'model_stat': unet.state_dict(),\n",
    "            'optimizer_stat': optimizer.state_dict(),\n",
    "        }\n",
    "        torch.save(checkpoint, os.path.join(os.getcwd(), \"{:04d}_{:04d}_{:04d}.pth\".format(int(eval_valid*1000),\n",
    "                                                                                   int(eval_train*1000),\n",
    "                                                                                   int(loss[0]*1000))))\n",
    "        print(\"Model Saved\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlimited-luxembourg",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acquired-happening",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create figure and axis objects with subplots()\n",
    "fig, axs = plt.subplots(2, 1, figsize=(20, 20))\n",
    "# make a plot\n",
    "axs[0].plot(epoch_logs['iou-valid'], color=\"orange\")\n",
    "# set x-axis label\n",
    "axs[0].set_xlabel(\"epoch\",fontsize=14)\n",
    "# set y-axis label\n",
    "axs[0].set_ylabel(\"valid-iou\",color=\"orange\",fontsize=14)\n",
    "\n",
    "\n",
    "# twin object for two different y-axis on the sample plot\n",
    "ax2 = axs[0].twinx()\n",
    "# make a plot with different y-axis using second axis object\n",
    "ax2.plot(epoch_logs['iou-train'], color=\"blue\")\n",
    "ax2.set_ylabel(\"train-iou\", color=\"blue\", fontsize=14)\n",
    "\n",
    "\n",
    "\n",
    "axs[1].plot(epoch_logs['diceloss'])\n",
    "axs[1].plot(epoch_logs['kl divergence'])\n",
    "axs[1].plot(epoch_logs['diagonal loss'])\n",
    "axs[1].set_xlabel(\"epoch\",fontsize=14)\n",
    "axs[1].set_ylabel(\"loss\", color=\"blue\", fontsize=14)\n",
    "plt.show()\n",
    "\n",
    "fig.savefig(os.path.join('logs.png'),\n",
    "            bbox_inches='tight',\n",
    "           facecolor='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advanced-subsection",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "manufactured-electric",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increased-capture",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "announced-phoenix",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "headed-scotland",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affecting-repository",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
