{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "endangered-origin",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import segmentation_models_pytorch as smp\n",
    "from torch.utils.data import DataLoader, Subset, ConcatDataset\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "tutorial-chosen",
   "metadata": {},
   "outputs": [],
   "source": [
    "import model\n",
    "import dataset\n",
    "import augmentation as aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "capable-michigan",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# helper function for data visualization\n",
    "def visualize(**images):\n",
    "    \"\"\"PLot images in one row.\"\"\"\n",
    "    n = len(images)\n",
    "    plt.figure(figsize=(16, 5))\n",
    "    for i, (name, image) in enumerate(images.items()):\n",
    "        plt.subplot(1, n, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title(' '.join(name.split('_')).title())\n",
    "        plt.imshow(image, 'gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "italic-repeat",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, optimizer, dataloader, device):\n",
    "\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0\n",
    "    \n",
    "    dice_total = 0\n",
    "    kl_total = 0\n",
    "    dl_total = 0\n",
    "    \n",
    "    dice_loss = smp.utils.losses.DiceLoss()\n",
    "\n",
    "    for index, data in tqdm(enumerate(dataloader)):\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        img, msk, _ = data\n",
    "\n",
    "        img = img.to(device)\n",
    "        msk = msk.to(device)\n",
    "\n",
    "        pr, kl_loss, dl_loss = model(img)\n",
    "\n",
    "        ### Predicted mask loss\n",
    "        pr = pr.squeeze(1)\n",
    "        \n",
    "#         print(torch.max(pr), torch.min(pr))\n",
    "\n",
    "        dice = dice_loss(pr, msk)\n",
    "        kl = torch.mean(kl_loss)\n",
    "        dl = torch.mean(dl_loss)\n",
    "        \n",
    "#         print(dice, kl, dl)\n",
    "\n",
    "        loss = dice + kl + dl\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        dice_total += dice.item()\n",
    "        kl_total += kl.item()\n",
    "        dl_total += dl.item()\n",
    "\n",
    "    total_loss = total_loss/(index+1)\n",
    "    dice_total = dice_total/(index+1)\n",
    "    kl_total = kl_total/(index+1)\n",
    "    dl_total = dl_total/(index+1)\n",
    "\n",
    "    return total_loss, dice_total, dl_total, dl_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "political-elements",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def eval_epoch(model, dataloader, device):\n",
    "\n",
    "    import math\n",
    "    from torch.utils.data import DataLoader\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    iou_score = []\n",
    "    \n",
    "    metric_iou = smp.utils.metrics.IoU()\n",
    "\n",
    "    for index, data in tqdm(enumerate(dataloader)):\n",
    "\n",
    "        img, msk, _ = data\n",
    "\n",
    "        img = img.to(device)\n",
    "        msk = msk.to(device)\n",
    "\n",
    "        pr, _, _ = model(img)\n",
    "        iou = metric_iou(pr, msk)\n",
    "\n",
    "        iou_score.append(iou.item())\n",
    "\n",
    "    return sum(iou_score)/len(iou_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "authorized-value",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test_epoch(model, dataset, device):\n",
    "\n",
    "    import math\n",
    "    from torch.utils.data import DataLoader\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    imgs = []\n",
    "    predict = []\n",
    "    msks = []\n",
    "\n",
    "    dataloader = DataLoader(dataset, batch_size=1,\n",
    "                            shuffle=False, num_workers=2)\n",
    "\n",
    "    for index, data in tqdm(enumerate(dataloader)):\n",
    "\n",
    "        img, msk, cpy = data\n",
    "\n",
    "        img = img.to(device)\n",
    "        msk = msk.to(device)\n",
    "\n",
    "        pr = model(img)\n",
    "\n",
    "        pr = torch.squeeze(pr, dim=0).detach().cpu().numpy()\n",
    "        msk = torch.squeeze(msk, dim=0).detach().cpu().numpy()\n",
    "        cpy = torch.squeeze(cpy, dim=0).detach().cpu().numpy()\n",
    "\n",
    "        predict.append(pr.transpose(1, 2, 0))\n",
    "        imgs.append(cpy.transpose(1, 2, 0))\n",
    "        msks.append(msk)\n",
    "\n",
    "\n",
    "    return imgs, predict, msks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "detailed-continent",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 4\n",
    "n_channels = 3\n",
    "n_classes = 1\n",
    "epochs = 1000\n",
    "\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "leading-london",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENCODER = 'densenet161'\n",
    "ENCODER_WEIGHTS = 'imagenet'\n",
    "\n",
    "preprocessing_fn = smp.encoders.get_preprocessing_fn(ENCODER, ENCODER_WEIGHTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ordinary-directory",
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = smp.Unet(encoder_name=ENCODER, \n",
    "                 encoder_weights=ENCODER_WEIGHTS,\n",
    "                decoder_attention_type=None,\n",
    "                 in_channels=3, classes=1, activation=\"sigmoid\", aux_params=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "requested-sequence",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = unet.encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "spiritual-paradise",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = model.SCGDecoder(None, None, torch.nn.Sigmoid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "radical-morris",
   "metadata": {},
   "outputs": [],
   "source": [
    "scg_net = model.SCGNet(encoder=encoder, \n",
    "               decoder=decoder,).to(device)\n",
    "\n",
    "optimizer = torch.optim.SGD(scg_net.parameters(), lr=1e-4, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "compatible-punishment",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainset = dataset.JSRTset(root=os.path.join(os.getcwd(), \"data\", \"trainset\"),\n",
    "                          augmentation=aug.get_training_augmentation(), \n",
    "                           preprocessing=aug.get_preprocessing(preprocessing_fn),)\n",
    "valset = dataset.JSRTset(root=os.path.join(os.getcwd(), \"data\", \"valset\"),\n",
    "                          augmentation=aug.get_validation_augmentation(), \n",
    "                           preprocessing=aug.get_preprocessing(preprocessing_fn),)\n",
    "testset = dataset.JSRTset(root=os.path.join(os.getcwd(), \"data\", \"testset\"),\n",
    "                          augmentation=aug.get_validation_augmentation(), \n",
    "                           preprocessing=aug.get_preprocessing(preprocessing_fn),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "spread-resolution",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(trainset, batch_size=batch, shuffle=True, num_workers=2)\n",
    "validloader = DataLoader(valset, batch_size=batch, shuffle=False, num_workers=2)\n",
    "testloader = DataLoader(testset, batch_size=batch, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "permanent-weekly",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increasing-spine",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "overall-custom",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_logs = {\n",
    "    \"diceloss\": [],\n",
    "    \"kl divergence\": [],\n",
    "    \"diagonal loss\": [],\n",
    "    \"iou-train\": [],\n",
    "    \"iou-valid\": []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developmental-ticket",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "41it [00:09,  4.30it/s]\n",
      "41it [00:07,  5.47it/s]\n",
      "8it [00:01,  5.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, total loss=2.78479, dice loss=0.99716, kl loss=0.00067, dl loss=0.00067\n",
      "Valid-IoU: 0.00424, Train-IoU: 0.00529\n",
      "Model Saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "41it [00:09,  4.37it/s]\n",
      "41it [00:07,  5.53it/s]\n",
      "8it [00:01,  5.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, total loss=1.44083, dice loss=0.99708, kl loss=0.00066, dl loss=0.00066\n",
      "Valid-IoU: 0.00411, Train-IoU: 0.00540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "41it [00:09,  4.39it/s]\n",
      "41it [00:07,  5.52it/s]\n",
      "8it [00:01,  5.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, total loss=1.26611, dice loss=0.99738, kl loss=0.00067, dl loss=0.00067\n",
      "Valid-IoU: 0.00409, Train-IoU: 0.00588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "41it [00:09,  4.40it/s]\n",
      "41it [00:07,  5.51it/s]\n",
      "8it [00:01,  5.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, total loss=1.19314, dice loss=0.99700, kl loss=0.00067, dl loss=0.00067\n",
      "Valid-IoU: 0.00414, Train-IoU: 0.00579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "41it [00:09,  4.41it/s]\n",
      "41it [00:07,  5.46it/s]\n"
     ]
    }
   ],
   "source": [
    "iou_valid = 0.0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    loss = train_epoch(scg_net, optimizer, trainloader, device)\n",
    "    eval_train = eval_epoch(scg_net, trainloader, device)\n",
    "    eval_valid = eval_epoch(scg_net, validloader, device)\n",
    "    \n",
    "    print(\"Epoch: {}, total loss={:.5f}, dice loss={:.5f}, kl loss={:.5f}, dl loss={:.5f}\".format(epoch, \n",
    "                                                                                                  loss[0],\n",
    "                                                                                                 loss[1],\n",
    "                                                                                                 loss[2],\n",
    "                                                                                                 loss[3]))\n",
    "    print(\"Valid-IoU: {:.5f}, Train-IoU: {:.5f}\".format(eval_valid, eval_train))\n",
    "    \n",
    "    epoch_logs['diceloss'].append(loss[1])\n",
    "    epoch_logs['kl divergence'].append(loss[2])\n",
    "    epoch_logs['diagonal loss'].append(loss[3])\n",
    "    epoch_logs['iou-train'].append(eval_train)\n",
    "    epoch_logs['iou-valid'].append(eval_valid)\n",
    "   \n",
    "    if epoch == int(epochs*0.5):\n",
    "        optimizer.param_groups[0]['lr'] = 1e-4\n",
    "        print('Decrease learning rate to 1e-4!')\n",
    "    elif epoch == int(epochs*0.75):\n",
    "        optimizer.param_groups[0]['lr'] = 1e-5\n",
    "        print('Decrease learning rate to 1e-5!')\n",
    "        \n",
    "    if eval_valid > iou_valid:\n",
    "        iou_valid = eval_valid\n",
    "        checkpoint = {\n",
    "            'model_stat': unet.state_dict(),\n",
    "            'optimizer_stat': optimizer.state_dict(),\n",
    "        }\n",
    "        torch.save(checkpoint, os.path.join(os.getcwd(), \"{:04d}_{:04d}_{:04d}.pth\".format(int(eval_valid*1000),\n",
    "                                                                                   int(eval_train*1000),\n",
    "                                                                                   int(loss[0]*1000))))\n",
    "        print(\"Model Saved\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfied-switch",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equivalent-paradise",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "virgin-wages",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "found-netherlands",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "talented-december",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "private-train",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "athletic-laundry",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "violent-casino",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
